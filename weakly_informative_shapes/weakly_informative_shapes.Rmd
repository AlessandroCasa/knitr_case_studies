---
title: "How the Shape of a Weakly Informative Prior Effects Inferences"
author: "Michael Betancourt"
date: "January 2017"
output:
  html_document:
    fig_caption: yes
    theme: cerulean
---

Weakly-informed priors are a somewhat vague concept where the user identifies
appropriate scales in a given analysis and uses those scales to introduce
important regularization into the analysis.  Exactly how those scales are
utilized, however, is ill-defined and the implementation of weakly-informative
priors can consequently be quite ambiguous for practitioners.

In this case study I will consider two approaches for implementing
weakly-informative priors and demonstrate how the specific properties of each
effect the resulting analysis.  

# Collinear Regression

Weakly-informative priors are especially critical when the inferences are
impaired with non-identifiable likelihoods, such as a collinear regression.
To that end, let's say that we are analyzing a small company and we want to
model how much daily rainfall, $x$, affects daily income, $y$, using only
a single datum.

For this study we will simulate data assuming that the company typically makes
a few thousand dollars, or kilodollars (k$), per day without any rain and that
a heavy rainfall of a few centimeters per day can severely curtain our income,
```{r}
library(rstan)
rstan_options(auto_write = TRUE)
```
```{r}
alpha <- 1    # k$
beta <- -0.25 # k$ / cm
sigma <- 1    # k$

N <- 1
x <- array(runif(N, 0, 2), dim=N)                    # cm
y <- array(rnorm(N, beta * x + alpha, sigma), dim=N) # k$

stan_rdump(c("N", "x", "y"), file="collinear_regression.data.R")
```

Assuming that both rainfall and income are sufficiently large, we can ignore
the fact that they are positive quantities and model their relationship with
a linear regression,
```{r}
writeLines(readLines("regression_no_prior.stan"))
```

Let's fit this linear regression in Stan using a very long Markov chain to
ensure precise quantification of our posterior distribution,
```{r, cache=TRUE}
input_data <- read_rdump("collinear_regression.data.R")

fit <- stan(file='regression_no_prior.stan', data=input_data,
            iter=11000, warmup=1000, chains=1, seed=483892929)
```

Unfortunately, this naive linear regression blows up,
```{r}
print(fit)
```

with the Markov chain meandering towards extreme values of the intercept
and slope,
```{r}
c_light <- c("#DCBCBC")
c_light_highlight <- c("#C79999")
c_mid <- c("#B97C7C")
c_mid_highlight <- c("#A25050")
c_dark <- c("#8F2727")
c_dark_highlight <- c("#7C0000")
```
```{r}
params <- as.data.frame(extract(fit, permuted=FALSE))
names(params) <- gsub("chain:1.", "", names(params), fixed = TRUE)

par(mar = c(4, 4, 0.5, 0.5))
plot(params$alpha, params$beta, col=c_dark, pch=16, cex=0.8,
     xlab="alpha (k$)",
     ylab="beta (k$ / cm)")
```

In hindsight this poor fit isn't unexpected.  With only a single data point
the three-dimensional likelihood is non-identified, and with flat priors on all
of our parameters the posterior becomes ill-posed.  If we want to regularize
our inferences then we need to incorporate better prior information into our
analysis.

# Diffuse Does Not Mean Non-informative!

Why is the prior information contained in a flat prior so useless in our
collinear regression?  Although flat priors are often motivated as being
"non-informative", they are actually very informative and pull the posterior
towards extreme values that can bias our inferences.

To see this, consider a flat prior for the intercept, $\alpha$, and the
question of how much prior probability mass is in the interval
$-1 \le \alpha \le 1$.  Because we can't normalize the prior there is no
well-defined answer, but we can at least consider the mass inside the interval
relative to the mass outside of the interval which is, well, infinite!  Hence
there is infinitely more prior mass that pulls inferences outside of the
interval $-1 \le \alpha \le 1$.

This logic, however, is exactly the same for the the interval
$-10 \le \alpha \le 10$, the $-100 \le \alpha \le 100$, and in fact any
finite interval.  The flat prior favors the exterior of the interval, pulling
our posterior and any resulting inferences towards extreme values.

Although it is tempting to blame this pathological behavior on the fact that
flat priors are not well-defined probability distributions and hence cannot be
normalized, the behavior is not unique to flat priors.  This bias towards
extreme values is characteristic of any prior that is very diffuse and places
significant probability mass at large values.  In practice, priors such as
$\alpha \sim U(-1000, 1000)$ and $\alpha \sim \mathcal{N}(0, 1000)$ can
bias our inferences as strongly as a flat prior.

The real issue is that these diffuse priors are _incoherent_ with our actual
prior beliefs.  For example, basic physical and economic constraints limit the
reasonable values of our parameters, and besides our linear model isn't even
valid for negative parameter values.  Diffuse priors pull the posterior towards
these extreme values, conflicting with even the most basic prior information.

Ultimately the misconception about diffuse priors being non-informative comes
from reasoning about priors _relative_ to the likelihood.  Because diffuse
priors distribute probability across such a large region of parameter space,
likelihoods that identify much smaller regions of parameter space quickly
overwhelm the prior distribution and dominate the posterior distribution.  Hence
diffuse priors supposedly "let the data speak for themselves".  

In complex models, however, it typically takes a significant amount of data for
the likelihood to be able to identify a necessarily small region of parameter
space.  The more expensive and sparse the data _and_ the more complex the
likelihood, the more informative diffuse priors will be.  If we want to make
reasonable inferences in these models then we need better prior distributions
that are actually coherent with our prior beliefs.

# Weakly-Informative Priors

Weakly-informative priors introduce _scale_ information to regularize
inferences.  Scales are straightforward to reason about in applied problems,
especially when units are carefully laid out, and they provide just enough
information to regularize non-identified or weakly-identified likelihoods
without strongly biasing the inferences to a narrow region of parameter space.
In order to construct weakly-informative priors we need to first decompose
our model configuration space, define default values, identify scales, then
choose an explicit shape for our prior.

Before we can reason about scales we need to decompose our model configuration
space into components.  In other words, we need to find a parameterization of
our model configuration space where the parameters are particularly meaningful.  
For example, the parameterization we have used in our linear regression is
ideal as the intercept, slope, and measurement variability have intuitive
interpretations.  The intercept, $\alpha$, determines the base income without
any rainfall, the slope, $\beta$, controls how a change in rainfall affects
income, and the measurement variation, $\sigma$, quantifies the natural
variability of daily income.

Next we need to modify this initial parameterization such that zero becomes
a reasonable default for our model.  This might require, for example, inverting
the individual parameters, if in the initial parameterization infinity is a more
natural default than zero.  The parameterization of our linear regression is
again already well-suited as a vanishing intercept, slope, or measurement
variability corresponds to a trivial system with no income or weather
interactions.

Once we have identified the appropriate parameterization we can determine
the scales coherent with our prior knowledge of the system.  Each scale softly
partitions the parameters into extreme values above and reasonable values below.
Perhaps the most straightforward way to reason about scales is to identify the
units that one would use to describe the system of interest before the
measurement.  If we are building an experiment to study nanoscale effects then
we wouldn't use kiloscale units, right?  Well we also wouldn't put any
significant prior probability on kiloscale effect sizes.  In practice it is
easier to make one last reparameterization into these natural units so that
all of our scales are around unity.

Finally we complete the specification of a weakly-informative prior by
complementing the scales with a shape to determine a probability distribution.
If we define the scale as $\delta$, then we could for example, take a uniform
distribution, $$\theta \sim U (-\delta, \delta),$$
but such an extreme cutoff removes not only extreme values far above the scale
but also the reasonable values just above the scale.  What we really want is a
shape that softly concentrates below the scale, such as a normal distribution,
$$\theta \sim \mathcal{N}(0, \delta),$$
a Cauchy distribution,
$$\theta \sim \mathrm{Cauchy}(0, \delta),$$
or even a Student-t distribution interpolating between the two.  If the
parameter of interest is positive then we typically truncate these distributions
at zero.

If we have chosen appropriate units then the scales reduce to unity and all of
our weakly-informative priors take a form like $\theta \sim \mathcal{N}(0, 1)$
or $\theta \sim \mathrm{Cauchy}(0, 1)$.  It is important to note however, that
these unit-scale priors alone do specify a weakly-informative priors!  _They are
weakly-informative only when our parameters have appropriate units._

In any case, all of these distributions strongly favor values within a few
factors of the scale while disfavoring those values much further away.  Although
there is recent work being done to develop formal criteria for selecting the
exact shape of the prior distribution, we will instead consider the exact shape
of a weakly-informative prior qualitatively affects the resulting inferences.

# Weakly-informative Priors Under Well-Chosen Scales

When the scales are well-chosen all weakly-informative priors behave similarly,
regularizing the posterior by penalizing extreme parameter values.  The exact
shape of a weakly-informative prior, however, does introduce some important
differences in how strong that regularization is.

# Light-Tailed Weakly Informed Priors

Let's first consider a relatively light-tailed weakly-informative prior that
utilizes gaussian and half-gaussian distributions.  Because we simulated the
data already in natural units, the weakly-informative priors are given simply
by unit-scale gaussians,
```{r}
writeLines(readLines("regression_gauss_wi_prior.stan"))
```
```{r, cache=TRUE}
gauss_fit <- stan(file='regression_gauss_wi_prior.stan', data=input_data,
                  iter=11000, warmup=1000, chains=1, seed=483892929)
```

We now have no problem fitting the model,
```{r}
print(gauss_fit)
```

and the now-regularized posterior accurately captures the parameters that we
used to simulate the data,
```{r}
gauss_params <- as.data.frame(extract(gauss_fit, permuted=FALSE))
names(gauss_params) <- gsub("chain:1.", "", names(gauss_params), fixed = TRUE)

par(mfrow=c(1, 3))

alpha_breaks=10 * (0:50) / 50 - 5
hist(gauss_params$alpha, main="", xlab="alpha (k$)", breaks=alpha_breaks,
     col=c_dark, border=c_dark_highlight,
     xlim=c(-5, 5))
abline(v=alpha, col=c_light, lty=1, lwd=3)

beta_breaks=10 * (0:50) / 50 - 5
hist(gauss_params$beta, main="", xlab="beta (k$ / cm)", breaks=beta_breaks,
     col=c_dark, border=c_dark_highlight,
     xlim=c(-5, 5))
abline(v=beta, col=c_light, lty=1, lwd=3)

sigma_breaks=5 * (0:50) / 50
hist(gauss_params$sigma, main="", xlab="sigma (k$)", breaks=sigma_breaks,
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 5))
abline(v=sigma, col=c_light, lty=1, lwd=3)
```

Given that we simulated so little data, our posterior is in fact dominated by
the weakly-informative priors.  Because these priors were chosen to be coherent
with our prior information, however, even a prior-dominated posterior yields
reasonable inferences!

# Heavy-Tailed Weakly Informed Priors

To contrast, let's now consider the more heavily-tailed priors given by
Cauchy and half-Cauchy distributions.  Once again our prescient choice of units
admits unit-scale distributions,
```{r}
writeLines(readLines("regression_cauchy_wi_prior.stan"))
```
```{r, cache=TRUE}
cauchy_fit <- stan(file='regression_cauchy_wi_prior.stan', data=input_data,
                  iter=11000, warmup=1000, chains=1, seed=483892929)
```

and once again the weakly-informative prior sufficiently regularizes our
inferences,
```{r}
print(cauchy_fit)
```

```{r}
cauchy_params <- as.data.frame(extract(cauchy_fit, permuted=FALSE))
names(cauchy_params) <- gsub("chain:1.", "", names(cauchy_params), fixed = TRUE)

par(mfrow=c(1, 3))

alpha_breaks=20 * (0:50) / 50 - 10
hist(cauchy_params$alpha[abs(cauchy_params$alpha) < 10],
     main="", xlab="alpha (k$)", breaks=alpha_breaks,
     col=c_dark, border=c_dark_highlight,
     xlim=c(-10, 10))
abline(v=alpha, col=c_light, lty=1, lwd=3)

beta_breaks=200 * (0:50) / 50 - 100
hist(cauchy_params$beta[abs(cauchy_params$beta) < 100],
     main="", xlab="beta (k$ / cm)", breaks=beta_breaks,
     col=c_dark, border=c_dark_highlight,
     xlim=c(-100, 100))
abline(v=beta, col=c_light, lty=1, lwd=3)

sigma_breaks=25 * (0:50) / 50
hist(cauchy_params$sigma[cauchy_params$sigma < 25],
     main="", xlab="sigma (k$)", breaks=sigma_breaks,
     col=c_dark, border=c_dark_highlight,
     xlim=c(0, 25))
abline(v=sigma, col=c_light, lty=1, lwd=3)
```

Relative to the gaussian prior, however, the Cauchy prior places a nontrivial
amount of posterior mass into the tails, far above the given scale,
```{r}
beta_breaks=200 * (0:100) / 100 - 100
gauss_hist <- hist(gauss_params$beta, breaks=beta_breaks, plot=FALSE)
cauchy_hist <- hist(cauchy_params$beta[abs(cauchy_params$beta) < 100],
                    breaks=beta_breaks, plot=FALSE)

par(mar = c(4, 4, 0.5, 0.5))
plot(cauchy_hist, col=c_light, border=c_light_highlight,
     main="", xlab="beta (k$ / cm")
plot(gauss_hist, col=c_dark, border=c_dark_highlight, add=T)
legend("topright", c("Gauss", "Cauchy"), fill=c(c_dark, c_light), bty="n")
```

This weaker regularization can seriously impact computational performance,
especially in models that utilize special functions that become difficult or
impossible to compute for extreme inputs, such as ODE solvers or gaussian
processes.  Although the Cauchy prior forces most of the posterior within the
specified scale, the heavy tail allows for the occasional extreme value that
stresses the special functions and drastically hinder computational performance.
Consequently, heavy-tailed weakly-informative priors must be employed with
care in practice.

# Weakly-informative Priors Under Poorly-Chosen Scales

The differing behavior of weakly-informative priors with different shapes
becomes particularly striking when the scales are poorly-chosen, and the
likelihood strongly favors conflicting parameter values.

To demonstrate this difference, let's simulate a larger data set where the
true intercept is above the scale of our chosen units,
```{r}
alpha <- 10    # k$
beta <- -0.25 # k$ / cm
sigma <- 1    # k$

N <- 10
x <- runif(N, 0, 2)                    # cm
y <- rnorm(N, beta * x + alpha, sigma) # k$

stan_rdump(c("N", "x", "y"), file="wrong_scale.data.R")
```

How this tension between the weakly-informative prior and the likelihood
manifests in the posterior is extremely sensitive to the exact shape of the
weakly-informative prior.

# The Failure Mode of Light Tails

Let's first consider the relatively light tail of a gaussian prior
distribution,
```{r, cache=TRUE}
input_data <- read_rdump("wrong_scale.data.R")

gauss_fit <- stan(file='regression_gauss_wi_prior.stan', data=input_data,
                  iter=11000, warmup=1000, chains=1, seed=483892929)
```

The light tail strongly penalizes parameter values above the chosen scale,
preventing the posterior from assigning any nontrivial probability mass to
the more extreme values favored by the likelihood,
```{r}
gauss_params <- as.data.frame(extract(gauss_fit, permuted=FALSE))
names(gauss_params) <- gsub("chain:1.", "", names(gauss_params), fixed = TRUE)

alpha_breaks=20 * (0:100) / 100 - 10
post_hist <- hist(gauss_params$alpha, breaks=alpha_breaks, plot=FALSE)
prior_hist <- hist(rnorm(10000, 0, 1), breaks=alpha_breaks, plot=FALSE)

par(mar = c(4, 4, 0.5, 0.5))
plot(prior_hist, col=c_light, border=c_light_highlight,
     main="", xlab="alpha (k$)")
plot(post_hist, col=c_dark, border=c_dark_highlight, add=T)
legend("topright", c("Posterior", "Prior"), fill=c(c_dark, c_light), bty="n")
```

Instead of contracting within the prior, the posterior ends up concentrating at
the boundary of the bulk of the prior mass, a few standard deviations away from
the prior mean.  This behavior is not immediately pathological and so
practitioners must take care to verify that their posteriors are actually
contracting and not accumulating near the tails of the prior.

# The Failure Mode of Heavy Tails

The heavier tail of the Cauchy prior behaves very differently to a poorly-chosen
scale distribution,
```{r, cache=TRUE}
input_data <- read_rdump("wrong_scale.data.R")

cauchy_fit <- stan(file='regression_cauchy_wi_prior.stan', data=input_data,
                  iter=11000, warmup=1000, chains=1, seed=483892929)
```

The light tail strongly penalizes parameter values above the chosen scale,
preventing the posterior from assigning any nontrivial probability mass to
the more extreme values favored by the likelihood,

Heavier tail less regularization allows the posterior to leak into the tail
of the prior,
```{r}
cauchy_params <- as.data.frame(extract(cauchy_fit, permuted=FALSE))
names(cauchy_params) <- gsub("chain:1.", "", names(cauchy_params), fixed = TRUE)

alpha_breaks=50 * (0:100) / 100 - 25
post_hist <- hist(cauchy_params$alpha, breaks=alpha_breaks, plot=FALSE)
prior_draws <- rcauchy(10000, 0, 1)
prior_hist <- hist(prior_draws[abs(prior_draws) < 25], breaks=alpha_breaks, plot=FALSE)

par(mar = c(4, 4, 0.5, 0.5))
plot(prior_hist, col=c_light, border=c_light_highlight,
     main="", xlab="alpha (k$)", ylim=c(0, 3000))
plot(post_hist, col=c_dark, border=c_dark_highlight, add=T)
legend("topright", c("Posterior", "Prior"), fill=c(c_dark, c_light), bty="n")
```

Again doesn't contract, but now the tension manifests in a much stronger
pathology.

# Discussion

An important consequence of the exact shape of a weakly informative prior is
the behavior when the chosen scale conflicts with the data.  The tension is much
easier to see in heavy tailed priors, but those priors also allow the posterior
to explore lots of extreme values even when the scale is well-chosen.

There is no unambiguous superior option.  Lighter tails are often useful for
complex models where sojourns into the tails requires huge amounts of computation
to evaluate the likelihood, although care must be taken when verifying the validity
of the chosen scale.  Heavy tailed priors are easier to validate but are best
when the likelihood is well-behaved even out in the tails.
